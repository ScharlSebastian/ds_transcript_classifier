{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from pandas.io.clipboard import copy\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def print_transcript_text(resp_list):\n",
    "\n",
    "    transcript_list = resp_list\n",
    "\n",
    "    duration_count = 0.0\n",
    "    \n",
    "    text_list_raw = []\n",
    "\n",
    "    for subtitle_info in transcript_list:\n",
    "        # starttime = subtitle_info[\"start\"]\n",
    "        duration = subtitle_info[\"duration\"]\n",
    "        subtitle_text = subtitle_info[\"text\"]\n",
    "\n",
    "        duration_count += duration\n",
    "        #print(subtitle_text[-1])\n",
    "        \n",
    "        text_list_raw.append(subtitle_text)\n",
    "        \n",
    "        if subtitle_text[-1] == \".\" and duration_count >= 30.0:\n",
    "            duration_count = 0.0\n",
    "            #print(\"\\n\")\n",
    "\n",
    "    text_list = ' '.join(text_list_raw)\n",
    "    text_list = text_list.replace(\". \",\".\\n\")\n",
    "    \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://youtu.be/SpvIZl1YQRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372\n",
      "By now, you've had a lot of practice with data processing and with defining RNNs.\n",
      "So, I'm not going to give you too much guidance here, when it comes to defining this model.\n",
      "Here's what it should look like generally.\n",
      "The model should be able to take in our word tokens, and the first thing that these go through will be an embedding layer.\n",
      "We have about 74,000 different words, and so this layer is going to be responsible for converting our word tokens, our integers into embeddings of a specific size.\n",
      "Now, you could train a Word2Vec model separately, and actually just use the learned word embeddings as input to an LSTM.\n",
      "But it turns out that these embedding layers are still useful even if they haven't been trained to learn the semantic relationships between words.\n",
      "So in this case, what we're mainly using this embedding layer for is dimensionality reduction.\n",
      "It will learn to look at our large vocabulary and map each word into a vector of a specified embedding dimension.\n",
      "Then, after our embedding layer, we have an LSTM layer.\n",
      "This is defined by a hidden state size and number of layers as you know.\n",
      "At each step, these LSTM cells will produce an output and a new hidden state.\n",
      "The hidden state will be passed to the next cell as input, and this is how we represent a memory in this model.\n",
      "The output is going to be fed into a Sigmoid activated fully connected output layer.\n",
      "This layer will be responsible for mapping the LSTM layer outputs to a desired output size.\n",
      "In this case, this should be the number of our sentiment classes, positive or negative.\n",
      "Then, the Sigmoid activation function is responsible for turning all of those outputs into a value between zero and one.\n",
      "This is the range we expect for our encoded sentiment labels.\n",
      "Zero is a negative and one is a positive review.\n",
      "So, this model is going to look at a sequence of words that make up a review.\n",
      "Here, we're interested in only the last Sigmoid output because this will produce the one label we're looking for at the end of processing a sequence of words in a review.\n",
      "So here's a little more explanation and some links to documentation if you need it.\n",
      "Then below, in this first cell, I'm going to check if a GPU is available for training.\n",
      "Then here, I want you to complete this model.\n",
      "It should take in all these parameters: our vocab size, output size, embedding dimension, hidden dimension, number of layers, and an optional dropout probability, and create an entire sentiment RNN model.\n",
      "You'll be responsible for completing the init and forward functions for this model.\n",
      "Remember that the output should just be the last value from our Sigmoid output layer.\n",
      "I'll also ask you to complete the init hidden function for the LSTM layer.\n",
      "This should initialize the hidden and cell state to be all zeros and move them to a GPU, if available.\n",
      "I'd encourage you to look at the documentation when helpful or your other code examples.\n",
      "You should have all the information you need to complete this model on your own.\n",
      "If you're confident in your model definition, later in this code, you'll be able to define your model hyperparameters and train it.\n",
      "Next, I'll show you one solution for defining the sentiment RNN model.\n",
      "But I do think this is a fun task to try out on your own in earnest too.\n",
      "I think it's a great exercise in thinking about how data is shaped as it moves through a model.\n",
      "So, good luck.\n"
     ]
    }
   ],
   "source": [
    "video_id = url.replace(\"https://youtu.be/\",\"\")\n",
    "resp_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "text_result = print_transcript_text(resp_list)\n",
    "print(len(text_result))\n",
    "print(text_result)\n",
    "copy(text_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
